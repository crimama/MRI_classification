{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"22.02.14_기본Pipeline.ipynb","provenance":[{"file_id":"18tastMh4sxkdMSRQ3ShsNVmFNnRdzc2e","timestamp":1644842158159}],"collapsed_sections":[],"machine_shape":"hm","background_execution":"on","mount_file_id":"18tastMh4sxkdMSRQ3ShsNVmFNnRdzc2e","authorship_tag":"ABX9TyPn3ki8O1nyQFg9qAzol0tK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 디렉토리 설정 "],"metadata":{"id":"I_iELta4J5NT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"25gmHRCYEzmf"},"outputs":[],"source":["!unzip /content/drive/MyDrive/DataSet/KYR_B_imaging.zip\n","!cp '/content/drive/MyDrive/Colab Notebooks/CT분류프로젝트/Custom_Py/init.py' ./"]},{"cell_type":"code","source":["!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr3' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr2 74' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr5' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr1' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr7' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr8' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr4' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/nswr1' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr6' '/content/KYR_B_imaging' \n","!rm -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱'"],"metadata":{"id":"3T5U1_vVWqS8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 초기작업"],"metadata":{"id":"zcZ1__VY3jdO"}},{"cell_type":"markdown","source":["## 기본 DF 생성 "],"metadata":{"id":"4vWmiBmR0ege"}},{"cell_type":"code","source":["import os \n","import cv2 \n","import pandas as pd \n","from glob import glob\n","from tqdm import tqdm\n","from init import init #초기 설정용 커스텀 패키지 \n","import numpy as np \n","import matplotlib.pyplot as plt \n","import matplotlib.pyplot as cm \n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"rosYzDen1l6T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###snsb_df 생성 "],"metadata":{"id":"DdMMgGvZ3iDe"}},{"cell_type":"code","source":["columns = ['성명',\n"," '병록번호',\n"," '만나이',\n"," '검사일',\n"," '교육년수',\n"," 'SVLT_recall_total_score_z',\n"," 'SVLT_Delayed_recall_z',\n"," 'SVLT_recognition_score_z',\n"," 'RCFT_immediate_recall_z',\n"," 'RCFT_delayed_recall_z',\n"," 'RCFT_recognition_score_z',\n"," 'K_MMSE_total_score_z',\n"," 'SNSB_II_Domain_Attention_z',\n"," 'SNSB_II_Domain_Language_z',\n"," 'SNSB_II_Domain_Visuospatial_z',\n"," 'SNSB_II_Domain_Memory_z',\n"," 'SNSB_II_Domain_Frontal_z']\n","\n","snsb_df = pd.read_csv('/content/drive/MyDrive/DataSet/202202_김예림/SNSB_integerated.csv')\n","snsb_df = snsb_df.drop([2098,2591]) #병록번호 없는 행 제거 <- 결측치 \n","snsb_df['병록번호'] = snsb_df['병록번호'].apply(lambda x : str(int(x)))\n","\n","snsb_df = snsb_df[columns]"],"metadata":{"id":"ZJy_JgMFUqUQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###dir_df 생성 "],"metadata":{"id":"V7h0NIEotoIc"}},{"cell_type":"code","source":["#폴더 디렉토리\n","folder_dir = glob('/content/KYR_B_imaging/*')\n","dir_df = init.dir_df(folder_dir)\n","dir_df = dir_df.sort_values(by=['dir'])"],"metadata":{"id":"kerrOcyYidyv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 병록번호- key 값 보정"],"metadata":{"id":"D2-wVYErkt2_"}},{"cell_type":"code","source":["target_length = [4,5,6,7,8] #<- 수정해야 하는 병록번호 갯수들 \n","\n","dir_df,snsb_df = init.key_mismatch(dir_df,snsb_df,target_length)\n","# plt.hist(snsb_df['병록번호'].map(len))\n","# plt.show()\n","\n","#에러값들 제외 \n","errors = ['000758836-1' '030338456-1' '040145556-1' '050236926-1' '090374796-1'\n"," '100402746-1' '120010356-1' '870133669-1' '920033543-1' '930236559-1'\n"," '930257597-1' '970682600-1']\n","\n","dir_df = dir_df.drop(np.where(dir_df['key'].apply(lambda x : x in errors))[0])"],"metadata":{"id":"IlQnCKnF06He"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##이미지 장수 조절\n"],"metadata":{"id":"8s0QWgYB5fLR"}},{"cell_type":"markdown","source":["### Key 별 이미지 갯수 리스트 생성 "],"metadata":{"id":"flyqxIBS-YmT"}},{"cell_type":"markdown","source":["Key 별 이미지 장수 확인 "],"metadata":{"id":"RQlnuMxJmPDx"}},{"cell_type":"code","source":["#이미지 장수 연산 \n","keys = list(set(dir_df['key'])) \n","images_length = pd.DataFrame(keys)[0].apply(lambda x: init.check_images(dir_df,x)) #키 값별로 이미지의 장수들 계산 \n","# images_length.value_counts()\n","\n","length_df = pd.DataFrame([keys,images_length]).T\n","length_df.columns = ['key','image_length']\n","length_df['image_length']  = length_df['image_length'].map(int)\n","\n","#Standard를 기준으로 less over 분할 \n","standard = 19 # 통일 시킬 이미지 장 수 기준 \n","\n","# 조정이 필요한 장 수 초과하는 것들만 추림 \n","length_df_over = length_df[length_df['image_length']>standard]\n","\n","#19장 보다 적은 경우 \n","# length_df_less = length_df[length_df['image_length']<standard]"],"metadata":{"id":"Mv8bk7a9mRze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### new_dir_df 생성 "],"metadata":{"id":"KiMO161I-boA"}},{"cell_type":"code","source":["new_dir_df = pd.DataFrame(np.zeros(1606*19*2).reshape(-1,2))\n","new_dir_df.columns = dir_df.columns\n","\n","for index in tqdm(range(1606)):\n","  new_dir_df.iloc[index*19:(index+1)*19,:]  = dir_df.loc[init.droped_indexes(dir_df,length_df_over,index,standard=19)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0T5XeyUeyOm","executionInfo":{"status":"ok","timestamp":1644839040172,"user_tz":-540,"elapsed":7727,"user":{"displayName":"­임훈 | ERICA 재료화학공학과","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"}},"outputId":"e8f49be9-3317-4328-9b24-0a86f19d07f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1606/1606 [00:07<00:00, 211.37it/s]\n"]}]},{"cell_type":"markdown","source":["## z score 임베딩 생성"],"metadata":{"id":"fggGNd-N0YfV"}},{"cell_type":"code","source":["Embedding_columns = snsb_df.columns[4:]\n","\n","for column in Embedding_columns:\n","  snsb_df[f'E_{column}'] = snsb_df[column].map(init.zscore_Embedding)\n","\n","#정렬 \n","snsb_df = snsb_df.sort_values(by=['병록번호'])\n","new_dir_df = new_dir_df.sort_values(by=['key'])\n","\n","csvs = snsb_df[snsb_df['병록번호'].apply(lambda x : x in key_lists)].sort_values(by=['병록번호'])\n","csvs = csvs.sort_values(by=['성명'])\n","csvs = csvs.drop_duplicates(['병록번호'], keep = 'first')\n","csvs = csvs.sort_values(['병록번호'])"],"metadata":{"id":"aqe-IPZm0hvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 로드 "],"metadata":{"id":"x4DZ7OS8nkyd"}},{"cell_type":"markdown","source":["## 제너레이터 사전 설정 "],"metadata":{"id":"2fOR-6Hj5Cqd"}},{"cell_type":"code","source":["input_columns = ['만나이','교육년수']\n","output_columns = ['E_SVLT_recall_total_score_z', 'E_SVLT_Delayed_recall_z',\n","       'E_SVLT_recognition_score_z', 'E_RCFT_immediate_recall_z',\n","       'E_RCFT_delayed_recall_z', 'E_RCFT_recognition_score_z',\n","       'E_K_MMSE_total_score_z', 'E_SNSB_II_Domain_Attention_z',\n","       'E_SNSB_II_Domain_Language_z', 'E_SNSB_II_Domain_Visuospatial_z',\n","       'E_SNSB_II_Domain_Memory_z', 'E_SNSB_II_Domain_Frontal_z']\n","\n","csvs_max = np.array([90,18])\n","csvs_min = np.array([45,0])"],"metadata":{"id":"WfdUHzsn8qQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#키값으로 이미지 dir 검색 \n","def temp_dir_df(new_dir_df,key):\n","  temp_df = new_dir_df[new_dir_df['key']==key]\n","  return temp_df\n","\n","#더미 넘파이에 한개씩 넣음 -> 19개 넣어서 19,512,512,3 shape 만듬 \n","def read_imgs(temp_df):\n","  temp_imgs = []\n","  for dir_index in range(19):\n","    temp_img = cv2.imread(temp_df['dir'].iloc[dir_index])\n","    temp_img = cv2.resize(temp_img,dsize= (256,256))\n","    # temp_img = cv2.cvtColor(temp_img,cv2.COLOR_BGR2GRAY)\n","    temp_imgs.append(temp_img)\n","  temp_imgs = np.array(temp_imgs)\n","  return temp_imgs\n","  \n","# 위 두개 통합 \n","def make_temp_imgs(new_dir_df,key):\n","  temp_df = temp_dir_df(new_dir_df,key)\n","  temp_imgs = read_imgs(temp_df)\n","  return temp_imgs"],"metadata":{"id":"BBIr3Nve7zBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#파라미터 \n","/"],"metadata":{"id":"TXPqURrMIws0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 제너레이터"],"metadata":{"id":"-ZRqwC5x4M0O"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import Sequence\n","import math\n","\n","\n","class DataGenerator(Sequence):\n","  def __init__(self,\n","                 key_lists,\n","                 new_dir_df,\n","                 csvs,\n","                 batch_size= 1,\n","                 validation_split = 0.1,\n","                 test_split = 0.1,\n","                 augmentation: bool = False,\n","                 shuffle: bool = False,\n","                 rescale:bool = True,\n","               indexes = None) -> None:\n","        self.key_lists = key_lists \n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.validation_split = validation_split\n","        self.augmentation = augmentation\n","        self.rescale =rescale\n","        self.new_dir_df = new_dir_df\n","        self.csvs = csvs\n","        self.indexes, self.valid_indexes, self.test_indexes = self._prepare_indexes(validation_split, test_split, indexes)\n","\n","\n","          # shuffle for first epoch\n","        if self.shuffle:\n","            self.shuffle_data()\n","\n","  def __len__(self):\n","    return math.ceil(len(self.key_lists) / self.batch_size)\n","  \n","  def __getitem__(self,index):\n","    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","    return self._generate_data(indexes)\n","\n","  def on_epoch_end(self):\n","        self._shuffle_index()\n","  \n","  def _prepare_indexes(self, validation_split, test_split, indexes):\n","        if indexes is not None:\n","            return indexes, None, None\n","        \n","        data_count = len(self.new_dir_df)\n","        all_index = np.arange(data_count)\n","\n","        if validation_split+test_split==0.0:\n","            return all_index, None, None\n","            \n","        valid_i = int(len(all_index)*(1-validation_split-test_split))\n","        test_i = int(len(all_index)*(1-test_split))\n","\n","        return all_index[:valid_i], all_index[valid_i:test_i], all_index[test_i:]\n","\n","  def _shuffle_index(self):\n","      if self.shuffle == True:\n","          np.random.shuffle(self.indexes)\n","  \n","  def _generate_data(self, indexes): #indexes = [0:1]\n","     csvs_input = self.csvs[input_columns].iloc[indexes]\n","     csvs_output = self.csvs[output_columns].iloc[indexes]\n","\n","     image_batch = self.key_lists[indexes]\n","     imgs = []\n","     for key_index in range(len(image_batch)):\n","       key = self.key_lists[key_index]\n","       temp_imgs = make_temp_imgs(self.new_dir_df,key)\n","       imgs.append(temp_imgs)\n","\n","     csvs_input = np.array(csvs_input)\n","     csvs_input = (csvs_input - csvs_min)/(csvs_max - csvs_min)\n","     csvs_output = np.array(csvs_output)\n","     imgs=  np.array(imgs)\n","     # return [imgs, csvs_input], csvs_output\n","     return imgs, csvs_output\n","\n","        \n","  def subset(self, type):\n","    if type==\"train\":\n","        return DataGenerator(self.key_lists,self.new_dir_df,self.csvs,indexes=self.indexes)\n","    elif type==\"validation\" or type==\"valid\":\n","        return DataGenerator(self.key_lists,self.new_dir_df,self.csvs, indexes=self.valid_indexes)\n","    elif type==\"test\":\n","        return DataGenerator(self.key_lists,self.new_dir_df,self.csvs, indexes=self.test_indexes)\n","    else:\n","        print(\"invalid type {}\".format(type))"],"metadata":{"id":"8THHtlUzEcHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import Sequence\n","import math\n","\n","\n","class DataGenerator(Sequence):\n","  def __init__(self,\n","                 key_lists,\n","                 new_dir_df,\n","                 snsb_df,\n","                 batch_size: int,\n","                 augmentation: bool = False,\n","                 shuffle: bool = False,\n","                 rescale:bool = True) -> None:\n","        self.key_lists = key_lists \n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.augmentation = augmentation\n","        self.rescale =rescale\n","        self.new_dir_df = new_dir_df\n","        self.csvs = csvs\n","\n","          # shuffle for first epoch\n","        if self.shuffle:\n","            self.shuffle_data()\n","\n","  def __len__(self):\n","    return math.ceil(len(self.key_lists) / self.batch_size)\n","\n","  def __getitem__(self, index):\n","    csvs_input = csvs[input_columns].iloc[index*self.batch_size:(index+1):self.batch_size,:]\n","    csvs_output = csvs[output_columns].iloc[index*self.batch_size:(index+1):self.batch_size,:]\n","\n","    image_batch = self.key_lists[index * self.batch_size:(index + 1) * self.batch_size]\n","    imgs = []\n","    for key_index in range(len(image_batch)):\n","      key = self.key_lists[key_index]\n","      temp_imgs = make_temp_imgs(self.new_dir_df,key)\n","      imgs.append(temp_imgs)\n","\n","    csvs_input = np.array(csvs_input)\n","    csvs_input = (csvs_input - csvs_min)/(csvs_max - csvs_min)\n","    csvs_output = np.array(csvs_output)\n","    imgs=  np.array(imgs)\n","    # return [imgs, csvs_input], csvs_output\n","    return imgs, csvs_output"],"metadata":{"id":"fktPgOpO4OCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_generator = DataGenerator(key_lists,new_dir_df,csvs,validation_split=0.2,test_split=0.1)\n","train_data_generator = data_generator.subset(\"train\")\n","valid_data_generator = data_generator.subset(\"valid\")\n","test_data_generator = data_generator.subset(\"test\")"],"metadata":{"id":"xQP5gdDe-cYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CsNIzfF1L0AE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델"],"metadata":{"id":"TuQap26j3YZW"}},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Bidirectional, LSTM, GRU\n","from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Dense,Flatten,Input,Conv3D,MaxPooling3D\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.applications import resnet50, efficientnet\n","from tensorflow.keras.applications import ResNet50, EfficientNetB0"],"metadata":{"id":"z0kalC333pos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.python import keras\n","input = Input((19,256,256,3))\n","x = BatchNormalization()(input)\n","x = Conv3D(256,kernel_size=(3,3,3),padding='same',activation='relu')(x)\n","x = MaxPooling3D((2,2,2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Conv3D(128,kernel_size=(3,3,3),padding='same',activation='relu')(x)\n","x = MaxPooling3D((2,2,2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Conv3D(64,kernel_size=(3,3,3),padding='same',activation='relu')(x)\n","x = MaxPooling3D((2,2,2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Conv3D(64,kernel_size=(3,3,3),padding='same',activation='relu')(x)\n","x = MaxPooling3D((2,2,2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Flatten()(x)\n","x = Dense(16,activation = 'relu')(x)\n","x = BatchNormalization()(x)\n","output = Dense(12,activation = 'softmax')(x)\n","\n","model = Model(input,output)\n","model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"o8nHEbuHfd0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_data_generator,validation_data = valid_data_generator, epochs=10,verbose=1)"],"metadata":{"id":"QbejWx3xj0XF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fdd63839-8e71-4090-bfee-375ad156a62f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"," 943/1606 [================>.............] - ETA: 3:27 - loss: 14.6542 - accuracy: 0.1092"]}]},{"cell_type":"code","source":["# copy from https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\n","# loss 실시간 출력 \n","from IPython.display import clear_output\n","from tensorflow.keras.callbacks import Callback\n","\n","class PlotLosses(Callback):\n","\n","  def on_train_begin(self, logs={}):\n","    self.epochs = []\n","    self.losses = []\n","    self.val_losses = []\n","    self.logs = []\n","    self.fig = plt.figure()\n","\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","\n","    self.epochs.append(epoch)\n","    self.losses.append(logs.get('loss'))\n","    self.val_losses.append(logs.get('val_loss'))\n","\n","    clear_output(wait=True)\n","    plt.plot(self.epochs, self.losses, label=\"loss\")\n","    plt.plot(self.epochs, self.val_losses, label=\"val_loss\")\n","    plt.legend()\n","    plt.show();\n","    print(\"loss = \", self.losses[-1], \", val_loss = \", self.val_losses[-1])\n","\n","#call backs 선언\n","plot_losses = PlotLosses()\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint #<- model 저장 객체, best_model.h5라는 모델 이 저장 됨 \n","model_check_point = ModelCheckpoint(\n","    'best_model.h5', \n","    monitor='val_loss', \n","    verbose=1, \n","    save_best_only=True)\n","\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 모니터링 대상, 이걸 기준으로 멈춤 \n","    verbose=1,\n","    patience=50)         # 중지까지의 여유분\n","\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss', # 모니터링 대상\n","    patience=25,        # 대상ㅃ 기간동안 유지\n","    factor=0.2,         # 줄이는 양                              \n","    min_learning_rate=0.00001)     # 최소 학습율\n","\n","callbacks = [model_check_point, plot_losses, reduce_lr]"],"metadata":{"id":"CCUqO4rXNJ0J"},"execution_count":null,"outputs":[]}]}