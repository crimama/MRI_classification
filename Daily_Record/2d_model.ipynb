{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crimama/MRI_classification/blob/main/Daily_Record/2d_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_iELta4J5NT"
      },
      "source": [
        "# 디렉토리 설정 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl5O4lUJ6fya",
        "outputId": "cdfa5101-cdd3-4264-e6ef-cc3d213975fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/DataSet/KYR_B_imaging.zip\n",
        "!cp '/content/drive/MyDrive/Colab Notebooks/프로젝트/ct분류/init.py' ./"
      ],
      "metadata": {
        "id": "zkeNmbTGSkaO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3T5U1_vVWqS8"
      },
      "outputs": [],
      "source": [
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr3' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr2 74' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr5' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr1' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr7' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr8' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr4' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/nswr1' '/content/KYR_B_imaging' \n",
        "!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr6' '/content/KYR_B_imaging' \n",
        "!rm -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcZ1__VY3jdO"
      },
      "source": [
        "# 초기작업\n",
        "- 데이터 제너레이터에 넣을 수 있는 기본형태를 만드는 것 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vWmiBmR0ege"
      },
      "source": [
        "## 기본 DF 생성 \n",
        "- csv 데이터인 snsb_df \n",
        "- 이미지 디렉토리 관련인 dir_df만듬 \n",
        "\n",
        "전처리 과정에서 \n",
        "- snsb_df -> csvs \n",
        "- dir_df -> new_dir_df로 변환 함 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rosYzDen1l6T"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2 \n",
        "import pandas as pd \n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from init import init #초기 설정용 커스텀 패키지 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.pyplot as cm \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from albumentations import (\n",
        "    Rotate,Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
        "    RandomBrightness, RandomContrast, RandomGamma,\n",
        "    ToFloat, ShiftScaleRotate,JpegCompression\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdMMgGvZ3iDe"
      },
      "source": [
        "###snsb_df 생성 \n",
        "- 환자 정보 데이터 프레임 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJy_JgMFUqUQ"
      },
      "outputs": [],
      "source": [
        "columns = ['성명',\n",
        " '병록번호',\n",
        " '만나이',\n",
        " '검사일',\n",
        " '교육년수',\n",
        " 'SVLT_recall_total_score_z',\n",
        " 'SVLT_Delayed_recall_z',\n",
        " 'SVLT_recognition_score_z',\n",
        " 'RCFT_immediate_recall_z',\n",
        " 'RCFT_delayed_recall_z',\n",
        " 'RCFT_recognition_score_z',\n",
        " 'K_MMSE_total_score_z',\n",
        " 'SNSB_II_Domain_Attention_z',\n",
        " 'SNSB_II_Domain_Language_z',\n",
        " 'SNSB_II_Domain_Visuospatial_z',\n",
        " 'SNSB_II_Domain_Memory_z',\n",
        " 'SNSB_II_Domain_Frontal_z']\n",
        "\n",
        "snsb_df = pd.read_csv('/content/drive/MyDrive/DataSet/202202_김예림/SNSB_integerated.csv')\n",
        "snsb_df = snsb_df.drop([2098,2591]) #병록번호 없는 행 제거 <- 결측치 \n",
        "snsb_df['병록번호'] = snsb_df['병록번호'].apply(lambda x : str(int(x))) #소수점으로 되어 있는 것 처리하고 str형 변형 \n",
        "\n",
        "snsb_df = snsb_df[columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7h0NIEotoIc"
      },
      "source": [
        "###dir_df 생성 \n",
        "- 환자  별 mri 디렉토리 데이터 프레임 \n",
        "- 이미지 장수 정리 안된 데이터 프레임 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kerrOcyYidyv"
      },
      "outputs": [],
      "source": [
        "#폴더 디렉토리\n",
        "folder_dir = glob('/content/KYR_B_imaging/*')\n",
        "dir_df = init.dir_df(folder_dir)\n",
        "dir_df = dir_df.sort_values(by=['key','dir'])\n",
        "dir_df = dir_df.reset_index().drop(columns = 'index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2-wVYErkt2_"
      },
      "source": [
        "### 병록번호- key 값 보정\n",
        "- 병록번호 == key 하게 만들어야 함 -> primary key \n",
        "- 중복 제거, @@@-1 형태 제거, 9자리로 통일 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlQnCKnF06He"
      },
      "outputs": [],
      "source": [
        "target_length = [4,5,6,7,8] #<- 수정해야 하는 병록번호 갯수들 \n",
        "\n",
        "dir_df,snsb_df = init.key_mismatch(dir_df,snsb_df,target_length)\n",
        "#인덱스 초기화 \n",
        "dir_df = dir_df.reset_index().drop(columns = 'index')\n",
        "# plt.hist(snsb_df['병록번호'].map(len))\n",
        "# plt.show()\n",
        "\n",
        "#에러값들 제외 \n",
        "errors = ['000758836-1' '030338456-1' '040145556-1' '050236926-1' '090374796-1'\n",
        " '100402746-1' '120010356-1' '870133669-1' '920033543-1' '930236559-1'\n",
        " '930257597-1' '970682600-1']\n",
        "\n",
        "dir_df = dir_df.drop(np.where(dir_df['key'].map(len)>9)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s0QWgYB5fLR"
      },
      "source": [
        "## new_dir_df 생성 - 이미지 장수 통일 \n",
        "- 위에서 만든 dir_df에서 각 key 별로 이미지 19장으로 맞춤 \n",
        "- 19장으로 맞추는 이유는 가장 비율이 높아서 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0iCEN_oc40h"
      },
      "source": [
        "### key 값 별 이미지 장수 연산 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ0qOVhtjdjK",
        "outputId": "a824b207-0a3d-4e20-e6d3-c86f8ab23761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1606"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#이미지 장수 연산 \n",
        "keys = list(set(dir_df['key'])) \n",
        "images_length = pd.DataFrame(keys)[0].apply(lambda x: init.check_images(dir_df,x)) #키 값별로 이미지의 장수들 계산 \n",
        "# images_length.value_counts()\n",
        "\n",
        "length_df = pd.DataFrame([keys,images_length]).T\n",
        "length_df.columns = ['key','image_length']\n",
        "length_df['image_length']  = length_df['image_length'].map(int)\n",
        "\n",
        "#Standard를 기준으로 less over 분할 \n",
        "standard = 19 # 통일 시킬 이미지 장 수 기준 \n",
        "\n",
        "# 조정이 필요한 장 수 초과하는 것들만 추림 \n",
        "length_df_over = length_df[length_df['image_length']>standard]\n",
        "\n",
        "#19장 보다 적은 경우 \n",
        "# length_df_less = length_df[length_df['image_length']<standard]\n",
        "\n",
        "len(length_df_over)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiMO161I-boA"
      },
      "source": [
        "### key값 별로 이미지 19장 있는 new_dir_df 생성 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0T5XeyUeyOm",
        "outputId": "e1830388-59cd-4c02-d628-bb31ec7414b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1606/1606 [00:07<00:00, 221.05it/s]\n"
          ]
        }
      ],
      "source": [
        "new_dir_df = pd.DataFrame(np.zeros(len(length_df_over)*19*2).reshape(-1,2))\n",
        "new_dir_df.columns = dir_df.columns\n",
        "\n",
        "for index in tqdm(range(len(length_df_over))):\n",
        "  new_dir_df.iloc[index*19:(index+1)*19,:]  = dir_df.loc[init.droped_indexes(dir_df,length_df_over,index,standard=19)]\n",
        "new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n",
        "new_dir_df = new_dir_df.reset_index().drop(columns = 'index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fggGNd-N0YfV"
      },
      "source": [
        "## csvs 생성 \n",
        " - 중복 제거 \n",
        " - z score -1.0를 기준으로 0(정상) 1(비정상)으로 분류 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqe-IPZm0hvy",
        "outputId": "2e01e105-67cf-4527-cff8-ec5188a4aa7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1606 1606\n"
          ]
        }
      ],
      "source": [
        "#19장의 사진으로 추린 new_dir_df로 새로운 키 리스트만듬) \n",
        "\n",
        "key_lists = np.unique(new_dir_df['key'])\n",
        "key_lists.sort()\n",
        "\n",
        "Embedding_columns = snsb_df.columns[5:]\n",
        "\n",
        "for column in Embedding_columns:\n",
        "  snsb_df[f'E_{column}'] = snsb_df[column].map(init.zscore_Embedding)\n",
        "\n",
        "#정렬 \n",
        "snsb_df = snsb_df.sort_values(by=['병록번호'])\n",
        "new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n",
        "\n",
        "#snsb_df 중 key_lists에 있는 행들만 추림 -> csvs \n",
        "csvs = snsb_df[snsb_df['병록번호'].apply(lambda x : x in key_lists)].sort_values(by=['병록번호'])\n",
        "csvs = csvs.reset_index().drop(columns = 'index')\n",
        "\n",
        "#중복 제거 : 이름으로 정렬 후 중복 제거 \n",
        "csvs = csvs.sort_values(by=['성명'])\n",
        "csvs = csvs.drop_duplicates(['병록번호'], keep = 'first')\n",
        "\n",
        "#다시 병록번호 로 정렬 해서 csvs 와 new_dir_df 순을 맞춤 \n",
        "csvs = csvs.sort_values(['병록번호'])\n",
        "csvs = csvs.reset_index().drop(columns = 'index')\n",
        "new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n",
        "new_dir_df = new_dir_df.reset_index().drop(columns = 'index')\n",
        "\n",
        "#맞춤 확인 \n",
        "print(len(csvs),len(np.unique(new_dir_df['key'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ML5r7Z4i0U"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQ6WGP4LF-I"
      },
      "source": [
        "## Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbX4pUJcLJDY"
      },
      "outputs": [],
      "source": [
        "#이미지 콘트라스트 변경 \n",
        "def img_Contrast(img): \n",
        "  import cv2 \n",
        "  lab = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "  lab = cv2.cvtColor(lab, cv2.COLOR_BGR2LAB)\n",
        "  l, a, b = cv2.split(lab)\n",
        "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) \n",
        "  cl = clahe.apply(l)\n",
        "  limg = cv2.merge((cl, a, b))\n",
        "  final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "  return final \n",
        "\n",
        "#가우시안 블러 \n",
        "def gaussianblur(image):\n",
        "  import cv2 \n",
        "  import numpy as np \n",
        "  blur = cv2.GaussianBlur(image, (5,5), np.random.randint(0,3,1))\n",
        "  return blur\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "transform = A.Compose([\n",
        "    RandomBrightness(limit=0.1),\n",
        "    JpegCompression(quality_lower=85, \n",
        "                    quality_upper=100, p=0.5), \n",
        "    HueSaturationValue(hue_shift_limit=20,\n",
        "                        sat_shift_limit=30, \n",
        "                    val_shift_limit=20, p=0.5),\n",
        "    RandomContrast(limit=0.2, p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n",
        "\n",
        "\n",
        "#랜덤 어그먼테이션 \n",
        "def random_aug(aug_image):\n",
        "  import numpy as np \n",
        "  import cv2 \n",
        "  n = np.random.randint(0,3,1)\n",
        "  if n == 0:\n",
        "    aug_image = cv2.flip(aug_image,np.random.randint(0,2,1))\n",
        "  if n == 1:\n",
        "    aug_image = gaussianblur(aug_image)\n",
        "  if n== 2:\n",
        "    pass\n",
        "  return aug_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaVmNxsN-JvR"
      },
      "source": [
        "## 이미지 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-z0VSeyBA6b"
      },
      "outputs": [],
      "source": [
        "def plot_img(temp_img):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.imshow(temp_img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thvDsi6n-GgV"
      },
      "outputs": [],
      "source": [
        "#이미지 전처리 \n",
        "\n",
        "def img_preprocess(img):\n",
        "  shape = img.shape[0]\n",
        "  preprocessed_img = img[int(shape*0.05):int(shape*0.95),int(shape*0.1):int(shape*0.9),:] #crop \n",
        "  preprocessed_img = transform(image=preprocessed_img)['image']\n",
        "  preprocessed_img = cv2.cvtColor(preprocessed_img,cv2.COLOR_BGR2GRAY)\n",
        "  preprocessed_img = cv2.resize(preprocessed_img,dsize=(224,224)) #resize Albu mentations -> vision 관련 augmentation document \n",
        "  preprocessed_img = preprocessed_img/255.\n",
        "  return preprocessed_img \n",
        "\n",
        "\n",
        "#더미 넘파이 만든 후 거기다 224,224 grayscale 이미지 넣음\n",
        "#디렉토리 df로 이미지 만듬 \n",
        "# def read_imgs(indexed_df):   2D 17,224,224,3 용 \n",
        "#     temp_img_1 = img_preprocess(cv2.imread(indexed_df['dir']))\n",
        "#     temp_img_2 = img_preprocess(cv2.imread(indexed_df['dir_1']))\n",
        "#     temp_img_3 = img_preprocess(cv2.imread(indexed_df['dir_2']))\n",
        "#     temp_imgs = np.stack([temp_img_1,temp_img_2,temp_img_3],axis=2)\n",
        "#     temp_imgs = random_aug(temp_imgs) #어그먼테이션 \n",
        "#     return temp_imgs\n",
        "\n",
        "def key_to_dir(key,new_dir_df):\n",
        "  dir_of_key = new_dir_df[new_dir_df['key']==key]\n",
        "  return dir_of_key\n",
        "\n",
        "\n",
        "\n",
        "def read_imgs(img_dir_df): #224, 224, 19 용 \n",
        "  temp_imgs = np.zeros(224*224*19).reshape(224,224,19)\n",
        "  for i in range(len(img_dir_df)):\n",
        "    temp_img = img_dir_df['dir'].iloc[i]\n",
        "    temp_img = img_preprocess(cv2.imread(temp_img))\n",
        "    temp_imgs[:,:,i] = temp_img \n",
        "  return temp_imgs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4DZ7OS8nkyd"
      },
      "source": [
        "# 데이터 제너레이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fOR-6Hj5Cqd"
      },
      "source": [
        "## 사전설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfdUHzsn8qQp"
      },
      "outputs": [],
      "source": [
        "input_columns = ['만나이','교육년수']\n",
        "output_columns = ['E_SVLT_recall_total_score_z', 'E_SVLT_Delayed_recall_z',\n",
        "       'E_SVLT_recognition_score_z', 'E_RCFT_immediate_recall_z',\n",
        "       'E_RCFT_delayed_recall_z', 'E_RCFT_recognition_score_z',\n",
        "       'E_K_MMSE_total_score_z', 'E_SNSB_II_Domain_Attention_z',\n",
        "       'E_SNSB_II_Domain_Language_z', 'E_SNSB_II_Domain_Visuospatial_z',\n",
        "       'E_SNSB_II_Domain_Memory_z', 'E_SNSB_II_Domain_Frontal_z']\n",
        "output_column = output_columns[0]\n",
        "\n",
        "csvs_max = np.array([90,18])\n",
        "csvs_min = np.array([45,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제너레이터"
      ],
      "metadata": {
        "id": "FSR1kXEMkG7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "키 리스트를 이용해 train, valid, test 분리 "
      ],
      "metadata": {
        "id": "bLmJgFD4odNg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2W_q0UKNRwm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "  def __init__(self,\n",
        "                 new_dir_df,\n",
        "                 csvs,\n",
        "                 key_lists,\n",
        "                 output_columns,\n",
        "                 batch_size: int,\n",
        "                 augmentation: bool = False,\n",
        "                 shuffle: bool = False,\n",
        "                 rescale:bool = True) -> None:\n",
        "        self.input_columns = input_columns \n",
        "        self.key_lists = key_lists\n",
        "        self.output_columns = output_columns\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentation = augmentation\n",
        "        self.rescale =rescale\n",
        "        self.new_dir_df = new_dir_df\n",
        "        self.csvs = csvs\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(len(self.key_lists) / self.batch_size)\n",
        "    \n",
        "  def on_epoch_end(self):\n",
        "    self.indices = np.arange(len(self.key_lists))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indices)\n",
        "      self.key_lists = self.key_lists[self.indices]\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    self.batch_keys = self.key_lists[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    self.batch_keys.sort()\n",
        "\n",
        "    #imgs \n",
        "    temp_imgs = []\n",
        "    for key in range(len(self.batch_keys)):\n",
        "      img_dir_df = key_to_dir(self.batch_keys[key],self.new_dir_df)\n",
        "      temp_img = read_imgs(img_dir_df)\n",
        "      temp_imgs.append(temp_img)\n",
        "    input_imgs = np.array(temp_imgs).astype(np.float)\n",
        "\n",
        "    #input_csvs\n",
        "    temp_csvs = self.csvs[self.csvs['병록번호'].apply(lambda x: x in self.batch_keys)]\n",
        "    temp_csvs = temp_csvs.sort_values(by=['병록번호'])\n",
        "    temp_csvs = temp_csvs.reset_index().drop(columns='index')\n",
        "    input_csvs = temp_csvs[input_columns]\n",
        "    input_csvs = np.array(input_csvs)\n",
        "\n",
        "    #output_csvs\n",
        "    temp_csvs = self.csvs[self.csvs['병록번호'].apply(lambda x: x in self.batch_keys)]\n",
        "    temp_csvs = temp_csvs.sort_values(by=['병록번호'])\n",
        "    temp_csvs = temp_csvs.reset_index().drop(columns='index')\n",
        "    output_csvs = temp_csvs[self.output_columns]\n",
        "    output_csvs = np.array(output_csvs)\n",
        "\n",
        "    return [input_imgs,input_csvs],output_csvs\n",
        "    # return input_imgs,output_csvs\n",
        "\n",
        "    \n",
        "# train = 1120\n",
        "# valid = 1360\n",
        "train = 160\n",
        "valid = 200\n",
        "train_generator = DataGenerator(new_dir_df,\n",
        "                                csvs,\n",
        "                                key_lists[:train],\n",
        "                                output_columns[0],\n",
        "                                batch_size=16,\n",
        "                                shuffle=True)\n",
        "valid_generator = DataGenerator(new_dir_df,\n",
        "                                csvs,\n",
        "                                key_lists[train:valid],\n",
        "                                output_columns[0],\n",
        "                                batch_size=16,\n",
        "                                shuffle=False)\n",
        "test_generator = DataGenerator(new_dir_df,\n",
        "                               csvs,\n",
        "                               key_lists[valid:240],\n",
        "                               output_columns[0],\n",
        "                               batch_size=16,\n",
        "                               shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.on_epoch_end\n",
        "a,b = next(iter(train_generator))\n",
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwvS92clwx4E",
        "outputId": "ff04b28c-2d2b-43d4-c74a-77021b6676a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zG5rfQ9OaJn"
      },
      "source": [
        "#모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw4xryIZObDe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, GRU, Activation, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Dense,Flatten,Input,Conv3D,MaxPooling3D\n",
        "from tensorflow.keras.layers import Conv3D, ConvLSTM2D, BatchNormalization, Input, Dropout, Bidirectional, Conv1D, MaxPooling1D,Reshape\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.applications import resnet50, efficientnet,VGG19\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0, DenseNet169, MobileNet,EfficientNetB4, ResNet152V2, EfficientNetV2B0\n",
        "import math\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.layers.pooling import GlobalAveragePooling2D,GlobalAveragePooling3D,AveragePooling3D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 사전 정의"
      ],
      "metadata": {
        "id": "ulO-mbhWkLpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n",
        "res50.trainable = False\n",
        "\n",
        "vgg19 = DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n",
        "vgg19.trainable = False\n",
        "\n",
        "effv2 = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n",
        "effv2.trainable = False"
      ],
      "metadata": {
        "id": "4ZSgm-0Jn1-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54be6801-fb42-4ddb-ea73-37dd0e366800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_to_pre(image_input): #224,224,19\n",
        "  x = Conv2D(16, (2,2), padding ='same',activation = 'relu')(image_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  # x = Conv2D(8, (2,2), padding ='same',activation = 'relu')(x)\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  out = Conv2D(3, (2,2), padding ='same',activation = 'relu')(x)\n",
        "  return out \n",
        "\n",
        "def image_encoder_layer(filters,img_input):\n",
        "  img = Conv2D(filters,(3,3),padding='same')(img_input)\n",
        "  img = Dropout(0.2)(img)\n",
        "  img_output = BatchNormalization()(img)\n",
        "  return img_output\n",
        "\n",
        "\n",
        "def image_encoder(image_combined):\n",
        "  # img = image_encoder_layer(1024,image_combined)\n",
        "  # img = image_encoder_layer(512,image_combined)\n",
        "  # img = image_encoder_layer(256,image_combined)\n",
        "  img_out = image_encoder_layer(128,image_combined)\n",
        "  return img_out\n",
        "\n",
        "def csvs_layers(filters,csv_input):\n",
        "  csv = Dense(filters, activation = 'relu')(csv_input)\n",
        "  csv = Dropout(0.2)(csv)\n",
        "  csv_layer_out = BatchNormalization()(csv)\n",
        "  return csv_layer_out\n",
        "\n",
        "def csvs_decoder(csvs_input):\n",
        "  # csvs = csvs_layers(32,csvs_input)\n",
        "  # csvs = csvs_layers(64,csvs)\n",
        "  csvs_out = csvs_layers(128,csvs_input)\n",
        "  return csvs_out\n",
        "  \n"
      ],
      "metadata": {
        "id": "lF7MK9EWm-qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 콜백"
      ],
      "metadata": {
        "id": "DMTH6bms-jsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy from https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\n",
        "# loss 실시간 출력 \n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class PlotLosses(Callback):\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.epochs = []\n",
        "    self.losses = []\n",
        "    self.val_losses = []\n",
        "    self.logs = []\n",
        "    self.fig = plt.figure()\n",
        "\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "    self.epochs.append(epoch)\n",
        "    self.losses.append(logs.get('loss'))\n",
        "    self.val_losses.append(logs.get('val_loss'))\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    plt.plot(self.epochs, self.losses, label=\"loss\")\n",
        "    plt.plot(self.epochs, self.val_losses, label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show();\n",
        "    print(\"loss = \", self.losses[-1], \", val_loss = \", self.val_losses[-1])\n",
        "\n",
        "#call backs 선언\n",
        "plot_losses = PlotLosses()\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint #<- model 저장 객체, best_model.h5라는 모델 이 저장 됨 \n",
        "model_check_point = ModelCheckpoint(\n",
        "    'best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # 모니터링 대상, 이걸 기준으로 멈춤 \n",
        "    verbose=1,\n",
        "    patience=50)         # 중지까지의 여유분\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', # 모니터링 대상\n",
        "    patience=10,        # 대상ㅃ 기간동안 유지\n",
        "    factor=0.2,         # 줄이는 양                              \n",
        "    min_learning_rate=0.00001)     # 최소 학습율\n",
        "\n",
        "callbacks = [ plot_losses,reduce_lr]"
      ],
      "metadata": {
        "id": "dzJyi-d6-kgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 "
      ],
      "metadata": {
        "id": "bvxbuana-opU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image input \n",
        "image_input = Input((224,224,19))\n",
        "image = input_to_pre(image_input)\n",
        "\n",
        "# conv \n",
        "res = res50(image)\n",
        "res = image_encoder(res)\n",
        "\n",
        "# vgg = vgg19(image)\n",
        "# vgg = image_encoder(vgg)\n",
        "\n",
        "# eff = effv2(image)\n",
        "# eff = image_encoder(eff)\n",
        "\n",
        "# image combined \n",
        "# image_combined = concatenate([res,vgg,eff])\n",
        "# image_combined = Conv2D(128, (2,2), padding = 'same')(image_combined)\n",
        "image_out = GlobalAveragePooling2D()(res)\n",
        "\n",
        "\n",
        "#csv \n",
        "csvs_input = Input((2))\n",
        "csvs_out = csvs_decoder(csvs_input)\n",
        "\n",
        "\n",
        "#image csv combined \n",
        "combined = concatenate([image_out,csvs_out])\n",
        "\n",
        "#out \n",
        "out = Dense(2,activation='softmax')(combined)\n",
        "\n",
        "model = Model([image_input,csvs_input],out)\n"
      ],
      "metadata": {
        "id": "iM0FWiKeqT8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "iyOmY6tr_2kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4a34dd-b410-46a6-8a49-4020ed69c349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
            "                                9)]                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 224, 224, 16  1232        ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 224, 224, 16  64         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 224, 224, 16  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 224, 224, 3)  195         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " resnet50 (Functional)          (None, 7, 7, 2048)   23587712    ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, 7, 128)    2359424     ['resnet50[1][0]']               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 7, 7, 128)    0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          384         ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 7, 7, 128)   512         ['dropout_3[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 128)         0           ['batch_normalization_3[0][0]']  \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dropout_4[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256)          0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'batch_normalization_4[0][0]'] \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            514         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,950,549\n",
            "Trainable params: 2,362,293\n",
            "Non-trainable params: 23,588,256\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "metadata": {
        "id": "RaNzMTDYxUpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GVfKM_sc-aEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,validation_data = valid_generator, epochs=100,verbose=1,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "IV7hLPnp-elo",
        "outputId": "bf34843c-bd84-47f9-db0e-3a6d1b8287db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss =  0.4035031795501709 , val_loss =  0.9442345499992371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 55s 6s/step - loss: 0.4035 - accuracy: 0.8313 - val_loss: 0.9442 - val_accuracy: 0.6000 - lr: 1.6000e-06\n",
            "Epoch 51/100\n",
            " 6/10 [=================>............] - ETA: 17s - loss: 0.3969 - accuracy: 0.8333"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "DMTH6bms-jsN"
      ],
      "name": "2d_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}