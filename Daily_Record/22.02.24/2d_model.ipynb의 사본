{"cells":[{"cell_type":"markdown","metadata":{"id":"I_iELta4J5NT"},"source":["# 디렉토리 설정 "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wl5O4lUJ6fya","executionInfo":{"status":"ok","timestamp":1645676445961,"user_tz":-540,"elapsed":21921,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"}},"outputId":"1c8c032f-5c79-4ac9-db60-48073319ce4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip /content/drive/MyDrive/DataSet/KYR_B_imaging.zip\n","!cp '/content/drive/MyDrive/Colab Notebooks/CT분류프로젝트/Custom_Py/init.py' ./"],"metadata":{"id":"zkeNmbTGSkaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3T5U1_vVWqS8"},"outputs":[],"source":["!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr3' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr2 74' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr5' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr1' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr7' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr8' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr4' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/nswr1' '/content/KYR_B_imaging' \n","!cp -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱/swr6' '/content/KYR_B_imaging' \n","!rm -r '/content/KYR_B_imaging/20201224 DL_MRI_SNSB_임승욱'"]},{"cell_type":"markdown","metadata":{"id":"zcZ1__VY3jdO"},"source":["# 초기작업"]},{"cell_type":"markdown","metadata":{"id":"4vWmiBmR0ege"},"source":["## 기본 DF 생성 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rosYzDen1l6T"},"outputs":[],"source":["import os \n","import cv2 \n","import pandas as pd \n","from glob import glob\n","from tqdm import tqdm\n","from init import init #초기 설정용 커스텀 패키지 \n","import numpy as np \n","import matplotlib.pyplot as plt \n","import matplotlib.pyplot as cm \n","import warnings\n","warnings.filterwarnings('ignore')\n","from albumentations import (\n","    Rotate,Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n","    RandomBrightness, RandomContrast, RandomGamma,\n","    ToFloat, ShiftScaleRotate,JpegCompression\n",")"]},{"cell_type":"markdown","metadata":{"id":"DdMMgGvZ3iDe"},"source":["###snsb_df 생성 \n","- 환자 정보 데이터 프레임 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJy_JgMFUqUQ"},"outputs":[],"source":["columns = ['성명',\n"," '병록번호',\n"," '만나이',\n"," '검사일',\n"," '교육년수',\n"," 'SVLT_recall_total_score_z',\n"," 'SVLT_Delayed_recall_z',\n"," 'SVLT_recognition_score_z',\n"," 'RCFT_immediate_recall_z',\n"," 'RCFT_delayed_recall_z',\n"," 'RCFT_recognition_score_z',\n"," 'K_MMSE_total_score_z',\n"," 'SNSB_II_Domain_Attention_z',\n"," 'SNSB_II_Domain_Language_z',\n"," 'SNSB_II_Domain_Visuospatial_z',\n"," 'SNSB_II_Domain_Memory_z',\n"," 'SNSB_II_Domain_Frontal_z']\n","\n","snsb_df = pd.read_csv('/content/drive/MyDrive/DataSet/202202_김예림/SNSB_integerated.csv')\n","snsb_df = snsb_df.drop([2098,2591]) #병록번호 없는 행 제거 <- 결측치 \n","snsb_df['병록번호'] = snsb_df['병록번호'].apply(lambda x : str(int(x))) #소수점으로 되어 있는 것 처리하고 str형 변형 \n","\n","snsb_df = snsb_df[columns]"]},{"cell_type":"markdown","metadata":{"id":"V7h0NIEotoIc"},"source":["###dir_df 생성 \n","- 환자  별 mri 디렉토리 데이터 프레임 \n","- 이미지 장수 정리 안된 데이터 프레임 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kerrOcyYidyv"},"outputs":[],"source":["#폴더 디렉토리\n","folder_dir = glob('/content/KYR_B_imaging/*')\n","dir_df = init.dir_df(folder_dir)\n","dir_df = dir_df.sort_values(by=['key','dir'])\n","dir_df = dir_df.reset_index().drop(columns = 'index')"]},{"cell_type":"markdown","metadata":{"id":"D2-wVYErkt2_"},"source":["### 병록번호- key 값 보정\n","- 병록번호 == key 하게 만들어야 함 -> primary key \n","- 중복 제거, @@@-1 형태 제거, 9자리로 통일 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlQnCKnF06He"},"outputs":[],"source":["target_length = [4,5,6,7,8] #<- 수정해야 하는 병록번호 갯수들 \n","\n","dir_df,snsb_df = init.key_mismatch(dir_df,snsb_df,target_length)\n","#인덱스 초기화 \n","dir_df = dir_df.reset_index().drop(columns = 'index')\n","# plt.hist(snsb_df['병록번호'].map(len))\n","# plt.show()\n","\n","#에러값들 제외 \n","errors = ['000758836-1' '030338456-1' '040145556-1' '050236926-1' '090374796-1'\n"," '100402746-1' '120010356-1' '870133669-1' '920033543-1' '930236559-1'\n"," '930257597-1' '970682600-1']\n","\n","dir_df = dir_df.drop(np.where(dir_df['key'].map(len)>9)[0])"]},{"cell_type":"markdown","metadata":{"id":"8s0QWgYB5fLR"},"source":["## new_dir_df 생성 - 이미지 장수 통일 \n","- 위에서 만든 dir_df에서 각 key 별로 이미지 19장으로 맞춤 \n","- 19장으로 맞추는 이유는 가장 비율이 높아서 \n"]},{"cell_type":"markdown","metadata":{"id":"b0iCEN_oc40h"},"source":["### key 값 별 이미지 장수 연산 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4605,"status":"ok","timestamp":1645688054972,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"},"user_tz":-540},"id":"tJ0qOVhtjdjK","outputId":"3905c881-9901-4fad-fb40-ecd39743c470"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1606"]},"metadata":{},"execution_count":6}],"source":["#이미지 장수 연산 \n","keys = list(set(dir_df['key'])) \n","images_length = pd.DataFrame(keys)[0].apply(lambda x: init.check_images(dir_df,x)) #키 값별로 이미지의 장수들 계산 \n","# images_length.value_counts()\n","\n","length_df = pd.DataFrame([keys,images_length]).T\n","length_df.columns = ['key','image_length']\n","length_df['image_length']  = length_df['image_length'].map(int)\n","\n","#Standard를 기준으로 less over 분할 \n","standard = 19 # 통일 시킬 이미지 장 수 기준 \n","\n","# 조정이 필요한 장 수 초과하는 것들만 추림 \n","length_df_over = length_df[length_df['image_length']>standard]\n","\n","#19장 보다 적은 경우 \n","# length_df_less = length_df[length_df['image_length']<standard]\n","\n","len(length_df_over)"]},{"cell_type":"markdown","metadata":{"id":"KiMO161I-boA"},"source":["### key값 별로 이미지 19장 있는 new_dir_df 생성 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7888,"status":"ok","timestamp":1645688062855,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"},"user_tz":-540},"id":"W0T5XeyUeyOm","outputId":"edb7c461-7c4b-4a2d-cc8f-9134f770ee3c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1606/1606 [00:08<00:00, 200.12it/s]\n"]}],"source":["new_dir_df = pd.DataFrame(np.zeros(len(length_df_over)*19*2).reshape(-1,2))\n","new_dir_df.columns = dir_df.columns\n","\n","for index in tqdm(range(len(length_df_over))):\n","  new_dir_df.iloc[index*19:(index+1)*19,:]  = dir_df.loc[init.droped_indexes(dir_df,length_df_over,index,standard=19)]\n","new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n","new_dir_df = new_dir_df.reset_index().drop(columns = 'index')"]},{"cell_type":"markdown","metadata":{"id":"fggGNd-N0YfV"},"source":["## csvs 생성 \n"," - 중복 제거 \n"," - z score -1.0를 기준으로 0(정상) 1(비정상)으로 분류 \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1645688063215,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"},"user_tz":-540},"id":"aqe-IPZm0hvy","outputId":"2022f929-f765-4934-f4eb-4b0272eb0138"},"outputs":[{"output_type":"stream","name":"stdout","text":["1606 1606\n"]}],"source":["#19장의 사진으로 추린 new_dir_df로 새로운 키 리스트만듬) \n","\n","key_lists = np.unique(new_dir_df['key'])\n","key_lists.sort()\n","\n","Embedding_columns = snsb_df.columns[5:]\n","\n","for column in Embedding_columns:\n","  snsb_df[f'E_{column}'] = snsb_df[column].map(init.zscore_Embedding)\n","\n","#정렬 \n","snsb_df = snsb_df.sort_values(by=['병록번호'])\n","new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n","\n","#snsb_df 중 key_lists에 있는 행들만 추림 -> csvs \n","csvs = snsb_df[snsb_df['병록번호'].apply(lambda x : x in key_lists)].sort_values(by=['병록번호'])\n","csvs = csvs.reset_index().drop(columns = 'index')\n","\n","#중복 제거 : 이름으로 정렬 후 중복 제거 \n","csvs = csvs.sort_values(by=['성명'])\n","csvs = csvs.drop_duplicates(['병록번호'], keep = 'first')\n","\n","#다시 병록번호 로 정렬 해서 csvs 와 new_dir_df 순을 맞춤 \n","csvs = csvs.sort_values(['병록번호'])\n","csvs = csvs.reset_index().drop(columns = 'index')\n","new_dir_df = new_dir_df.sort_values(by=['key','dir'])\n","new_dir_df = new_dir_df.reset_index().drop(columns = 'index')\n","\n","#맞춤 확인 \n","print(len(csvs),len(np.unique(new_dir_df['key'])))"]},{"cell_type":"markdown","metadata":{"id":"W7ML5r7Z4i0U"},"source":["# 전처리"]},{"cell_type":"markdown","metadata":{"id":"FpQ6WGP4LF-I"},"source":["## Augmentation "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbX4pUJcLJDY"},"outputs":[],"source":["#이미지 콘트라스트 변경 \n","def img_Contrast(img): \n","  import cv2 \n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","  l, a, b = cv2.split(lab)\n","  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) \n","  cl = clahe.apply(l)\n","  limg = cv2.merge((cl, a, b))\n","  final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","  return final \n","#가우시안 블러 \n","def gaussianblur(image):\n","  import cv2 \n","  import numpy as np \n","  blur = cv2.GaussianBlur(image, (5,5), np.random.randint(0,3,1))\n","  return blur\n","\n","def transforms(image):\n","  transforms = Compose([Rotate(limit=40),\n","                      RandomBrightness(limit=0.1),\n","                      JpegCompression(quality_lower=85, \n","                                      quality_upper=100, p=0.5), \n","                      HueSaturationValue(hue_shift_limit=20,\n","                                         sat_shift_limit=30, \n","                                         val_shift_limit=20, p=0.5), \n","                      RandomContrast(limit=0.2, p=0.5), HorizontalFlip(), ])\n","  image = transforms(image)\n","  image = image['image']\n","  return image \n","\n","\n","#랜덤 어그먼테이션 \n","def random_aug(aug_image):\n","  import numpy as np \n","  import cv2 \n","  n = np.random.randint(0,4,1)\n","  if n == 0:\n","    aug_image = cv2.flip(aug_image,np.random.randint(0,2,1))\n","  if n == 1:\n","    try: \n","      aug_image = transforms(aug_image)\n","    except:\n","      pass\n","  if n ==2:\n","    aug_image = gaussianblur(aug_image)\n","  if n ==3:\n","    pass\n","  return aug_image\n"]},{"cell_type":"markdown","metadata":{"id":"ZaVmNxsN-JvR"},"source":["## 이미지 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-z0VSeyBA6b"},"outputs":[],"source":["def plot_img(temp_img):\n","  plt.figure(figsize=(10,10))\n","  plt.imshow(temp_img)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thvDsi6n-GgV"},"outputs":[],"source":["#이미지 전처리 \n","\n","def img_preprocess(img):\n","  shape = img.shape[0]\n","  preprocessed_img = img[int(shape*0.05):int(shape*0.95),int(shape*0.1):int(shape*0.9),:] #crop \n","  preprocessed_img = cv2.cvtColor(preprocessed_img, cv2.COLOR_BGR2GRAY)\n","  preprocessed_img = cv2.resize(preprocessed_img,dsize=(224,224)) #resize Albu mentations -> vision 관련 augmentation document \n","  preprocessed_img = preprocessed_img/255.\n","  # preprocessed_img = efficientnet.preprocess_input(preprocessed_img) \n","  return preprocessed_img \n","\n","\n","#더미 넘파이 만든 후 거기다 224,224 grayscale 이미지 넣음\n","#디렉토리 df로 이미지 만듬 \n","# def read_imgs(indexed_df):   2D 17,224,224,3 용 \n","#     temp_img_1 = img_preprocess(cv2.imread(indexed_df['dir']))\n","#     temp_img_2 = img_preprocess(cv2.imread(indexed_df['dir_1']))\n","#     temp_img_3 = img_preprocess(cv2.imread(indexed_df['dir_2']))\n","#     temp_imgs = np.stack([temp_img_1,temp_img_2,temp_img_3],axis=2)\n","#     temp_imgs = random_aug(temp_imgs) #어그먼테이션 \n","#     return temp_imgs\n","\n","def key_to_dir(key,new_dir_df):\n","  dir_of_key = new_dir_df[new_dir_df['key']==key]\n","  return dir_of_key\n","\n","\n","\n","def read_imgs(img_dir_df): #224, 224, 19 용 \n","  temp_imgs = np.zeros(224*224*19).reshape(224,224,19)\n","  for i in range(len(img_dir_df)):\n","    temp_img = img_dir_df['dir'].iloc[i]\n","    temp_img = img_preprocess(cv2.imread(temp_img))\n","    temp_img = temp_img.reshape(224,224,1)\n","    temp_imgs[:,:] = temp_img \n","  return temp_imgs\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x4DZ7OS8nkyd"},"source":["# 데이터 제너레이터"]},{"cell_type":"markdown","metadata":{"id":"2fOR-6Hj5Cqd"},"source":["## 사전설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfdUHzsn8qQp"},"outputs":[],"source":["input_columns = ['만나이','교육년수']\n","output_columns = ['E_SVLT_recall_total_score_z', 'E_SVLT_Delayed_recall_z',\n","       'E_SVLT_recognition_score_z', 'E_RCFT_immediate_recall_z',\n","       'E_RCFT_delayed_recall_z', 'E_RCFT_recognition_score_z',\n","       'E_K_MMSE_total_score_z', 'E_SNSB_II_Domain_Attention_z',\n","       'E_SNSB_II_Domain_Language_z', 'E_SNSB_II_Domain_Visuospatial_z',\n","       'E_SNSB_II_Domain_Memory_z', 'E_SNSB_II_Domain_Frontal_z']\n","\n","csvs_max = np.array([90,18])\n","csvs_min = np.array([45,0])"]},{"cell_type":"markdown","source":["## 제너레이터"],"metadata":{"id":"FSR1kXEMkG7m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2W_q0UKNRwm"},"outputs":[],"source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import Sequence\n","import math\n","\n","\n","class DataGenerator(Sequence):\n","  def __init__(self,\n","                 new_dir_df,\n","                 csvs,\n","                 key_lists,\n","                 output_columns,\n","                 batch_size: int,\n","                 augmentation: bool = False,\n","                 shuffle: bool = False,\n","                 rescale:bool = True) -> None:\n","        self.input_columns = input_columns \n","        self.key_lists = key_lists\n","        self.output_columns = output_columns\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.augmentation = augmentation\n","        self.rescale =rescale\n","        self.new_dir_df = new_dir_df\n","        self.csvs = csvs\n","\n","  def __len__(self):\n","    return math.ceil(len(self.key_lists) / self.batch_size)\n","    \n","  def on_epoch_end(self):\n","    self.indices = np.arange(len(self.key_lists))\n","    if self.shuffle == True:\n","      np.random.shuffle(self.indices)\n","      self.key_lists = self.key_lists[self.indices]\n","      \n","\n","\n","\n","  def __getitem__(self, index):\n","    self.batch_keys = self.key_lists[index*self.batch_size:(index+1)*self.batch_size]\n","    self.batch_keys.sort()\n","\n","    #imgs \n","    temp_imgs = []\n","    for key in range(len(self.batch_keys)):\n","      img_dir_df = key_to_dir(self.batch_keys[key],self.new_dir_df)\n","      temp_img = read_imgs(img_dir_df)\n","      temp_imgs.append(temp_img)\n","    input_imgs = np.array(temp_imgs).astype(np.float)\n","\n","    #ouput_csvs\n","    temp_csvs = self.csvs[self.csvs['병록번호'].apply(lambda x: x in self.batch_keys)]\n","    temp_csvs = temp_csvs.sort_values(by=['병록번호'])\n","    temp_csvs = temp_csvs.reset_index().drop(columns='index')\n","    input_csvs = temp_csvs[input_columns]\n","    input_csvs = np.array(input_csvs)\n","\n","    #output_csvs\n","    temp_csvs = self.csvs[self.csvs['병록번호'].apply(lambda x: x in self.batch_keys)]\n","    temp_csvs = temp_csvs.sort_values(by=['병록번호'])\n","    temp_csvs = temp_csvs.reset_index().drop(columns='index')\n","    output_csvs = temp_csvs[output_columns]\n","    output_csvs = np.array(input_csvs)\n","\n","    # return [input_imgs,input_csvs],output_csvs\n","    # return input_imgs,output_csvs\n","\n","    \n","# train = 964*17\n","# valid = 1285*17\n","train = 50\n","valid = 60\n","train_generator = DataGenerator(new_dir_df,\n","                                csvs,\n","                                key_lists[:train],\n","                                output_columns[0],\n","                                batch_size=8,\n","                                shuffle=True)\n","valid_generator = DataGenerator(new_dir_df,\n","                                csvs,\n","                                key_lists[train:valid],\n","                                output_columns[0],\n","                                batch_size=8,\n","                                shuffle=False)\n","test_generator = DataGenerator(new_dir_df,\n","                               csvs,\n","                               key_lists[valid:],\n","                               output_columns[0],\n","                               batch_size=8,\n","                               shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"5zG5rfQ9OaJn"},"source":["#모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zw4xryIZObDe"},"outputs":[],"source":["from tensorflow.keras import optimizers\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Bidirectional, LSTM, GRU, Activation, AveragePooling2D\n","from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Dense,Flatten,Input,Conv3D,MaxPooling3D\n","from tensorflow.keras.layers import Conv3D, ConvLSTM2D, BatchNormalization, Input, Dropout, Bidirectional, Conv1D, MaxPooling1D,Reshape\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.applications import resnet50, efficientnet,VGG19\n","from tensorflow.keras.applications import ResNet50, EfficientNetB0, DenseNet169, MobileNet,EfficientNetB4, ResNet152V2, EfficientNetV2B0\n","import math\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import plot_model\n","from keras.layers.pooling import GlobalAveragePooling2D,GlobalAveragePooling3D,AveragePooling3D\n"]},{"cell_type":"markdown","source":["## 모델 사전 정의"],"metadata":{"id":"ulO-mbhWkLpb"}},{"cell_type":"code","source":["res50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n","res50.trainable = False\n","\n","vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n","vgg19.trainable = False\n","\n","effv2 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224,3)) #size -> 256, 256 \n","effv2.trainable = False"],"metadata":{"id":"4ZSgm-0Jn1-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def input_to_pre(image_input=(224,224,19)):\n","  image_input = Input(image_input)\n","  x = Conv3D(256, (2,2,2), padding ='same',activation = 'relu')(image_input)\n","  x = MaxPooling3D()(x)\n","  x = Conv3D(128, (2,2,2), padding ='same',activation = 'relu')(x)\n","  x = MaxPooling3D()(x)\n","  out = Reshape((224,224,4))(x)\n","  return out \n","\n","def image_encoder_layer(filters,img_input):\n","  img = Conv2D(filters,(3,3),padding='same')(img_input)\n","  img = Dropout(0.2)(img)\n","  img_output = BatchNormalization()(img)\n","  return img_output\n","\n","\n","def image_encoder(image_combined):\n","  img = image_encoder_layer(1024,image_combined)\n","  img = image_encoder_layer(512,img)\n","  img = image_encoder_layer(256,img)\n","  img = image_encoder_layer(128,img)\n","  img_out = GlobalAveragePooling2D()(img)\n","  return img_out\n","\n","def csvs_layers(filters,csv_input):\n","  csv = Dense(filters, activation = 'relu')(csv_input)\n","  csv = Dropout(0.2)(csv)\n","  csv_layer_out = BatchNormalization()(csv)\n","  return csv_layer_out\n","\n","def csvs_decoder(csvs_input):\n","  csvs = csvs_layers(32,csvs_input)\n","  csvs = csvs_layers(64,csvs)\n","  csvs = csvs_layers(128,csvs)\n","  return csvs\n","  \n"],"metadata":{"id":"lF7MK9EWm-qy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 콜백"],"metadata":{"id":"DMTH6bms-jsN"}},{"cell_type":"code","source":["# copy from https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\n","# loss 실시간 출력 \n","from IPython.display import clear_output\n","from tensorflow.keras.callbacks import Callback\n","\n","class PlotLosses(Callback):\n","\n","  def on_train_begin(self, logs={}):\n","    self.epochs = []\n","    self.losses = []\n","    self.val_losses = []\n","    self.logs = []\n","    self.fig = plt.figure()\n","\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","\n","    self.epochs.append(epoch)\n","    self.losses.append(logs.get('loss'))\n","    self.val_losses.append(logs.get('val_loss'))\n","\n","    clear_output(wait=True)\n","    plt.plot(self.epochs, self.losses, label=\"loss\")\n","    plt.plot(self.epochs, self.val_losses, label=\"val_loss\")\n","    plt.legend()\n","    plt.show();\n","    print(\"loss = \", self.losses[-1], \", val_loss = \", self.val_losses[-1])\n","\n","#call backs 선언\n","plot_losses = PlotLosses()\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint #<- model 저장 객체, best_model.h5라는 모델 이 저장 됨 \n","model_check_point = ModelCheckpoint(\n","    'best_model.h5', \n","    monitor='val_loss', \n","    verbose=1, \n","    save_best_only=True)\n","\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 모니터링 대상, 이걸 기준으로 멈춤 \n","    verbose=1,\n","    patience=50)         # 중지까지의 여유분\n","\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss', # 모니터링 대상\n","    patience=10,        # 대상ㅃ 기간동안 유지\n","    factor=0.2,         # 줄이는 양                              \n","    min_learning_rate=0.00001)     # 최소 학습율\n","\n","callbacks = [ plot_losses,reduce_lr]"],"metadata":{"id":"dzJyi-d6-kgP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 "],"metadata":{"id":"bvxbuana-opU"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"S9O35y8oD5Wj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_input = Input((224,224,19))\n","x = Conv2D(16, (2,2), padding ='same',activation = 'relu')(image_input)\n","x = Conv2D(8, (2,2), padding ='same',activation = 'relu')(x)\n","x = Conv2D(4, (2,2), padding ='same',activation = 'relu')(x)\n","image_output = Conv2D(3, (2,2), padding='same')(x)\n","\n","\n","\n","vgg = vgg19(image_output)\n","vgg = Dropout(0.25)(vgg)\n","vgg = BatchNormalization()(vgg)\n","vgg = MaxPooling2D()(vgg)\n","\n","res = res50(image_output)\n","res = Dropout(0.25)(res)\n","res = BatchNormalization()(res)\n","res = MaxPooling2D()(res)\n","\n","eff = effv2(image_output)\n","eff = Dropout(0.25)(eff)\n","eff = BatchNormalization()(eff)\n","eff = MaxPooling2D()(eff)\n","image_combined = concatenate([vgg,res,eff])\n","image_output = image_encoder(image_combined)\n","\n","\n","#csvs \n","csvs_input = Input((2))\n","csvs_output = csvs_decoder(csvs_input)\n","\n","combined = concatenate([image_output,csvs_output])\n","x = Dense(32,activation='relu')(combined)\n","x= BatchNormalization()(x)\n","x = Dropout(0.2)(x)\n","out = Dense(2,activation = 'softmax')(x)\n","\n","model = Model([image_input,csvs_input],out)"],"metadata":{"id":"iM0FWiKeqT8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["4*56*56*128/448/448"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCny31DIC9SV","executionInfo":{"status":"ok","timestamp":1645695233795,"user_tz":-540,"elapsed":309,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"}},"outputId":"b93fcf15-f007-4b2d-dd35-ef6253e7b566"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8.0"]},"metadata":{},"execution_count":238}]},{"cell_type":"code","source":["model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"GVfKM_sc-aEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_generator,validation_data = valid_generator, epochs=100,verbose=1,callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IV7hLPnp-elo","executionInfo":{"status":"error","timestamp":1645695607340,"user_tz":-540,"elapsed":16990,"user":{"displayName":"­임훈","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15355961264808837253"}},"outputId":"3781d4bc-6a19-4c12-d5b0-b207a8ec4a7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-257-8e89ad069d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-257-8e89ad069d8c>\", line 1, in <module>\n      history = model.fit(train_generator,validation_data = valid_generator, epochs=100,verbose=1,callbacks=callbacks)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [8,2] and labels shape [16]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_314204]"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"2d_model.ipynb의 사본","provenance":[{"file_id":"1TbqrIX7UqxNUEEYfIVVBPF2mD-AT7aCT","timestamp":1645695723064},{"file_id":"1xGWMOsYCN90xmS3KtM7wbaByI6l9-ktm","timestamp":1645359842207},{"file_id":"1pZwwDcy03Jj_dM6dOU7Gi59mctIiJPVo","timestamp":1645266574968},{"file_id":"18tastMh4sxkdMSRQ3ShsNVmFNnRdzc2e","timestamp":1644885200151}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}